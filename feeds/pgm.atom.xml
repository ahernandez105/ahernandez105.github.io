<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>angel's blog - pgm</title><link href="/" rel="alternate"></link><link href="/feeds/pgm.atom.xml" rel="self"></link><id>/</id><updated>2019-01-01T00:00:00-05:00</updated><subtitle>My name is Angel C. Hernandez and I am a graduate student at Carnegie Mellon University focusing my studies in machine learning. I am also a recipient of the Science Mathematics and Research for Transformation (SMART) Fellowship, where upon graduation I will be an engineer for the army adhereing to initiatives in warfare simulation modeling at the TRADOC Analysis Center. I have found machine learning blog posts to be an excellent resource during my academic studies and I hope mine can be a benefit to you.</subtitle><entry><title>Variational Autoencoders</title><link href="/test-post.html" rel="alternate"></link><published>2019-01-01T00:00:00-05:00</published><updated>2019-01-01T00:00:00-05:00</updated><author><name>Angel C. Hernandez</name></author><id>tag:None,2019-01-01:/test-post.html</id><summary type="html">&lt;p&gt;SOME TEXT&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;link rel="stylesheet" 
type="text/css" 
href="/theme/css/md-style.css"&gt;&lt;/p&gt;
&lt;h1 class="head"&gt;1. Introduction &lt;/h1&gt;

&lt;p class="body"&gt;

Like all 
&lt;a href="https://openai.com/blog/generative-models/" style="color:#FF7D33"&gt;
generative models&lt;/a&gt;, VAEs are concerned with learning a valid probability distribution from which our dataset was &lt;i&gt;generated&lt;/i&gt; from. They do this by learning a set of latent variables, 
&lt;span class="math"&gt;\(\boldsymbol{z}\)&lt;/span&gt;,
which are essentially the underlining features that best explain our observed data
&lt;span class = "math"&gt;\(\boldsymbol{x}\)&lt;/span&gt;.
We can then condition on these variables and sample from the distribution, 
&lt;span class = "math"&gt;
\( 
\boldsymbol{x}_{new} \sim 
p(\boldsymbol{x}_{observed}|\boldsymbol{z}) \)
&lt;/span&gt;, 
to generate a new data point. This distribution happens to be tractable 
but using the posterior,
&lt;span class = "math"&gt;
\( 
\boldsymbol{z} \sim 
p(\boldsymbol{z}|\boldsymbol{x}_{observed}) \)
&lt;/span&gt;,
is the distribution that has plagued machine learning since the beginning of time.
Furthermore, it is challenging to learn the parameters of both distributions in an end-to-end fashion. &lt;a href='#wakeSleep' id='ref-wakeSleep-1'&gt;(Hinton et al., 1995)&lt;/a&gt; developed the Wake-sleep algorithm which was able to learn all parameters to this exact problem via two objective functions and back-propagation. While this algorithm &lt;i&gt; masked &lt;/i&gt; the problem at hand, even Geoffrey Hinton 
&lt;a href="https://www.youtube.com/watch?v=VKpc_z7b9I0" style="color:#FF7D33"&gt; 
acknowledged&lt;/a&gt;, and I quote, &lt;i&gt; "the basic idea behind these variational methods sounds crazy." &lt;/i&gt; Luckily, &lt;a href='#vae' id='ref-vae-1'&gt;(Diederik and Max, 2014)&lt;/a&gt; offered a better solution using the &lt;i&gt;
reparameterization trick &lt;/i&gt; and deep generative models have really been in resurgence since! 

&lt;/p&gt;

&lt;h1 class="head"&gt; 2. Problem Scenario &lt;/h1&gt;

&lt;script type="text/javascript"&gt;

if (!document.getElementById('mathjaxscript_pelican_#%&amp;#64;#$&amp;#64;#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%&amp;#64;#$&amp;#64;#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        fonts: ['STIX', 'TeX']," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}

&lt;/script&gt;&lt;hr&gt;
&lt;h2&gt;Bibliography&lt;/h2&gt;
&lt;p id='vae'&gt;Kingma Diederik and Welling Max.
Auto-encoding variational bayes.
2014.
URL: &lt;a href="https://arxiv.org/pdf/1312.6114.pdf"&gt;https://arxiv.org/pdf/1312.6114.pdf&lt;/a&gt;. &lt;a class="cite-backref" href="#ref-vae-1" title="Jump back to reference 1"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;p id='wakeSleep'&gt;Geoffrey Hinton, Peter Dayan, Brendan&amp;nbsp;J Frey, and Radford&amp;nbsp;M Neal.
The wake-sleep alogrithm for unsupervised neural networks.
1995.
URL: &lt;a href="http://www.cs.toronto.edu/~fritz/absps/ws.pdf"&gt;http://www.cs.toronto.edu/~fritz/absps/ws.pdf&lt;/a&gt;. &lt;a class="cite-backref" href="#ref-wakeSleep-1" title="Jump back to reference 1"&gt;↩&lt;/a&gt;&lt;/p&gt;
</content><category term="pgm"></category><category term="generative_models"></category></entry></feed>